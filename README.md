# ğŸ¯ Keystroke Synthesizer
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)](https://pytorch.org/)

> **Transform text into realistic keystroke patterns using deep learning**

A  neural network that learns individual typing behaviors and generates synthetic keystroke dynamics from text input. Built with transformer architecture and heteroscedastic regression for accurate timing prediction.

## ğŸŒŸ Features

- **ğŸ§  Advanced Architecture**: DeBERTa-v3 transformer with multi-head prediction
- **âš¡ Heteroscedastic Modeling**: Predicts both mean and uncertainty for realistic variation  
- **ğŸ“Š Comprehensive Metrics**: Dwell time, flight time, typing speed, and keystroke flags
- **ğŸ›¡ï¸ Numerical Stability**: Conservative bounds and gradient monitoring for robust training
- **ğŸ”„ Real-time Synthesis**: Generate keystroke sequences from any text input
- **ğŸ“ˆ Performance Tracking**: Built-in accuracy testing and visualization tools

## ğŸ—ï¸ Architecture

```
Text Input â†’ DeBERTa Tokenizer â†’ Transformer Encoder
                                        â†“
                               Shared Backbone (512â†’256)
                                        â†“
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â–¼             â–¼             â–¼
                    Mean Head    LogVar Head   Classification Head
                   (3 features)  (3 features)    (7 binary flags)
                          â†“             â†“             â†“
                    [DwellTime,   [Uncertainty]   [is_letter,
                     FlightTime,                   is_digit, ...]
                     typing_speed]
```

## ğŸ“¦ Installation

### Prerequisites
- Python 3.8+
- CUDA-compatible GPU (recommended)
- 8GB+ RAM

### Setup
```bash
# Clone the repository
git clone https://github.com/yourusername/keystroke-synthesizer.git
cd keystroke-synthesizer

# Install dependencies
pip install -r requirements.txt

# Download and prepare dataset (see Data section)
```

## ğŸš€ Quick Start

### Training a Model
```python
from Trainer.Trainer import Trainer

# Initialize and train
trainer = Trainer()
trainer.train()
```

### Generating Keystrokes
```python
from Testing.synthesizeKeystrokes import predict_keystrokes

# Generate keystroke pattern for text
text_path = "sample.txt"
predict_keystrokes(
    text_path=text_path,
    checkpoint_path="checkpoints/best_model.pt",
    output_csv="predicted_keystrokes.csv"
)
```

### Testing Accuracy
```python
from Testing.accuracyTester import compare

# Evaluate model performance
compare()  # Compares original vs synthetic keystroke statistics
```
```

## ğŸ“Š Data Pipeline

The system processes keystroke data through a robust pipeline:

1. **Data Preprocessing** (`dataPipeline/dataPrepper.py`)
   - Outlier detection and capping
   - Feature engineering and validation
   - Comprehensive NaN handling

2. **Data Loading** (`dataPipeline/dataLoader.py`) 
   - NaN-aware standardization
   - Statistics persistence via JSON
   - Efficient batch processing

3. **Model Training** (`Trainer/Trainer.py`)
   - Conservative numerical bounds
   - Enhanced gradient monitoring  
   - Early stopping with validation

## ğŸ›ï¸ Configuration

Key training parameters in [`Trainer/config.py`](Trainer/config.py):

```python
# Model Configuration
BASE_MODEL = "microsoft/deberta-v3-base"
MAX_TOKENS = 512

# Training Configuration  
EPOCHS = 12
BATCH_SIZE = 8
LR = 1e-5  # Conservative for stability
WEIGHT_DECAY = 0.01

# KL Regularization
KL_WEIGHT_START = 0.001
KL_WEIGHT_END = 0.03
KL_ANNEAL_EPOCHS = 8

# Feature-specific weights [DwellTime, FlightTime, typing_speed]
KL_FEATURE_WEIGHTS = [1.0, 0, 0.3]
```

## ğŸ“ˆ Results & Metrics

The model tracks multiple performance indicators:

- **Mean Absolute Error (MAE)**: Timing prediction accuracy
- **KL Divergence**: Uncertainty calibration quality  
- **Classification Accuracy**: Keystroke type prediction
- **Empirical Variance**: Realistic variation modeling

## ğŸ—‚ï¸ Project Structure

```
keystroke-synthesizer/
â”œâ”€â”€ ğŸ“ data/                    # Training data
â”‚   â”œâ”€â”€ csv/                    # Keystroke timing data
â”‚   â”œâ”€â”€ texts/                  # Corresponding text samples
â”‚   â””â”€â”€ predicted_csvs/         # Generated synthetic keystroke data
â”œâ”€â”€ ğŸ“ dataPipeline/           # Data processing pipeline
â”‚   â”œâ”€â”€ __init__.py            # Package initialization
â”‚   â”œâ”€â”€ dataPrepper.py         # Data cleaning & preprocessing
â”‚   â””â”€â”€ dataLoader.py          # Dataset loading & standardization
â”œâ”€â”€ ğŸ“ Trainer/                # Training components
â”‚   â”œâ”€â”€ __init__.py            # Package initialization
â”‚   â”œâ”€â”€ Trainer.py             # Main training class
â”‚   â”œâ”€â”€ TextToKeystrokeModelMultiHead.py  # Model architecture
â”‚   â”œâ”€â”€ HeteroscedasticKLLoss.py          # Loss function
â”‚   â”œâ”€â”€ config.py              # Training configuration
â”‚   â”œâ”€â”€ make_collate.py        # Batch processing
â”‚   â””â”€â”€ utils.py               # Training utilities
â”œâ”€â”€ ğŸ“ Testing/                # Evaluation and analysis tools
â”‚   â”œâ”€â”€ synthesizeKeystrokes.py # Text-to-keystroke generation
â”‚   â”œâ”€â”€ accuracyTester.py      # Model evaluation & comparison
â”‚   â””â”€â”€ grapher.py             # Results visualization
â”œâ”€â”€ ğŸ“ checkpoints/            # Saved models
â”œâ”€â”€ ğŸ“ graphs/                 # Performance visualizations
â”œâ”€â”€ ğŸ“ misc/                   # Miscellaneous utilities
â”œâ”€â”€ ğŸ“ runs/                   # Training logs and outputs
â””â”€â”€ README.md                  # This file
```

## ğŸ”¬ Technical Details

### Heteroscedastic Regression
The model predicts both mean timing and uncertainty (log-variance) for each keystroke feature, enabling realistic variation in generated patterns.

### Conservative Numerical Bounds
- Log-variance clamped to `[-0.5, 0.5]` â†’ variance âˆˆ `[0.6, 1.6]`
- Empirical variance bounds: `[0.5, 2.0]`  
- Variance ratio limits: `[0.1, 10.0]`

### Gradient Monitoring
Real-time detection of NaN/Inf gradients with immediate training termination to prevent model corruption.

## ğŸ“Š Dataset

**Source**: [KLiCKe Dataset](https://www.kaggle.com/datasets/julesking/tla-lab-pii-competition-dataset?resource=download-directory)

The dataset contains over 2,000 text-keystroke pairs with detailed timing information:
- **Dwell Time**: Key press duration
- **Flight Time**: Time between keystrokes  
- **Typing Speed**: Characters per minute
- **Keystroke Flags**: Letter, digit, punctuation, etc.

*Special thanks to the KLiCKe dataset contributors for making this research possible.*



## ğŸ™ Acknowledgments

- **Dataset**: [KLiCKe Competition Dataset](https://www.kaggle.com/datasets/julesking/tla-lab-pii-competition-dataset?resource=download-directory)
- **Model Architecture**: Microsoft DeBERTa-v3
- **Framework**: PyTorch & Hugging Face Transformers

---

<div align="center">

## Disclaimer:
    Credit to claude for making this readme look a lot nicer then I could ğŸ˜Š

</div>
